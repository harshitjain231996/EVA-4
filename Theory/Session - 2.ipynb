{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local receptive field = Size of the kernel\n",
    "\n",
    "While we are convolving the kernel, we want the redundancy to occur.\n",
    "\n",
    "Example:\n",
    "\n",
    "![i](https://i.imgur.com/2imfwju.jpg)\n",
    "\n",
    "In the image above, V.E. stands for vertical Edge.\n",
    "\n",
    "The first kernel will detect tht there is a vertical edge since it is present in the middle of the kernel. The second kernel will not detect a vertical edge since the vertical edge isn't present in it's middle. So we need redundancy since we need continuous reading of data which in turn will help us decide the accurate location of particular feature. We want the particular feature to be read again by kernel to indicate that the feature was present in the exact same location.\n",
    "\n",
    "The kernel is designed in such a way that either it needs a particular feature or does not need it. It is looking for a specific feature and the kernel will move out if it does not have the feature present in it's center. That is why we need an odd kernel and not an even kernel since an even kernel will not be able to figure out what particular feature is present in the center.\n",
    "\n",
    "Deep Neural Networks has 4 stages of identification :-\n",
    "\n",
    "Edges + Gradients -> Patterns + textures\n",
    "\n",
    "When the network instead of losing starts filtering, it actually becomes much better network.\n",
    "\n",
    "![i](https://i.imgur.com/ZZRYKBW.jpg)\n",
    "\n",
    "When we see -1 above, whatever pixel value we are seeing we need to take those and supress them because all the values are going to be added later on, so just make a (-)ve of it. So, whatever value is there on where negative value is, we need to supress that and wherever negative value isn't present, we need to amplify it. \n",
    "\n",
    "If in a given image the features are loud, we don't need a lot of those features to be there. We need to carry forward only those features which are loud enough. If it's not loud enough, then we are going to miss something. In that case, it is the task of backpropagation to fix the kernel to make it louder. The kernel is going to make it louder by making the values of kernel larger.\n",
    "\n",
    "If a feature is really important then the backpropagation is going to design a kernel to make that feature loud enough. If the feature is loud enough, only then it can go pass the max pooling layer.\n",
    "\n",
    "When the network is not able to carry forward certain features, then backpropagation is going to look at that kernel which can help fix the particular part and once it has figured out, slowly it will increase the particular value so that it can go pass the max pooling layer. We add max pooling layer so that we can reduce the size of channels we have and so we don't have to process that much or we don't have to add those many layers before we can reach our final output.\n",
    "\n",
    "THe most important features of an image should not be present in the last row and column since the last row and column will be lost when we are doing max pooling.\n",
    "\n",
    "GAP : When there are large pixel size very close to our output, we are going to use GAP(global average pooling). It means tht whatever values we have in the channel, we are going to sum them all up. We don't even need a parameter to calculate GAP of a channel\n",
    "\n",
    "Whenever we are doing padding, we generally add the value in the pixel as the one which is nearest or the neighbouring value of the pixel, So we shouldn't add any value from our own i.e. no adding of 0. We should only add value which is present in the neighbourhood. We are adding only the value which we already have present in the image.\n",
    "\n",
    "When we are about to do GAP, we do not want the last pixel i.e. the pixel just before where we are adding GAP to be vey small. We are doing prediction just before GAP, so the pixel shouldn't be very small since then predicting values will be really difficult as a lot of features shall be lost. But at the same time, it cannot be really very high because that would mean we are convolving on big channels and that means our GPU is getting used up a lot. So, we need to keep the pixel as large as possible but neither too small nor too large.\n",
    "\n",
    "The last layer of the network needs to know what is happening in the entire network but it cannot interact with all. It just get's the filtered information from many many different kernels which are present. We are going to do a skip connection which will allow the last layers to interact with intiial few layers just to get information from them. \n",
    "\n",
    "We are never going to use max pooling just before our final layer. We want to make max pooling layer as far as possible from output.\n",
    "\n",
    "We are going to take the image, we are going to perform some convolutions and then we are going to add max pooling after the receptive field is equal to the size of the features of the edges and gradients one can find for whihc one has to look at the dataset.\n",
    "\n",
    "If while writing the layer, we are not telling ourselves what is the receptive field and what is the output channel size, we are not going to write any model which is of any use.\n",
    "\n",
    "Max Pooling adds a bit of Shift Invariance, Rotational Invariance and Scale Invariance.\n",
    "\n",
    "BackPropagation looks at the network which we have written. \n",
    "\n",
    "MaxPooling is good since it can allow the kernel to handle small invariance. So, a kernel which is able to only identify 45 degree edges it can now at least identify 50 degree edges since the invariance is small.\n",
    "\n",
    "One kernel will always give one channel\n",
    "\n",
    "Number of outputs = Number of kernels\n",
    "\n",
    "The task of a kernel is to extract one specific feature while working on all the channels. \n",
    "\n",
    "A kernel will have as many channels as the input.\n",
    "\n",
    "The theory is not yet complete. Will complete it soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
